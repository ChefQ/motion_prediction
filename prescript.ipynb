{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from transformers import pipeline, set_seed\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "import regex as re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import ast\n",
    "import torch\n",
    "from huggingface_hub import scan_cache_dir\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import ast\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "import os\n",
    "from datasets import DatasetDict, concatenate_datasets\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from joblib import dump, load\n",
    "import argparse\n",
    "import joblib\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "#watch -n0.1 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load model\n",
    "\n",
    "cuda_count = torch.cuda.device_count()\n",
    "\n",
    "sentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# model_name  = \"Open-Orca/Mistral-7B-OpenOrca\" #\"mistralai/Mistral-7B-v0.1\n",
    "# config = AutoConfig.from_pretrained(model_name)\n",
    "# max_input_size =  config.max_position_embeddings  \n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, device=device, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIdsType(brief_type):\n",
    "    def getIds(briefs):\n",
    "\n",
    "        briefs = briefs[brief_type]\n",
    "        briefs_ids = []\n",
    "        briefs = ast.literal_eval(briefs)\n",
    "        for brief in briefs:\n",
    "            iD = tokenizer(brief, max_length = max_input_size, padding='max_length', truncation= True ,return_tensors=\"pt\") #.to(device).input_ids \n",
    "            briefs_ids.append(iD)\n",
    "        return { f\"ids_{brief_type}\": briefs_ids }\n",
    "    return getIds\n",
    "\n",
    "\n",
    "def meanEmbeddings(briefs):\n",
    "\n",
    "    briefs = ast.literal_eval(briefs)\n",
    "    # Place model inputs on the GPU\n",
    "    embeddings = []\n",
    "    for brief in briefs:\n",
    "        argument = tokenizer(brief, max_length = max_input_size , padding=\"max_length\" ,truncation= True ,return_tensors=\"pt\").to(device) \n",
    "        # Extract last hidden states\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            argument = argument.to(device)\n",
    "            output = model(**argument)\n",
    "            argument = argument.to(device)\n",
    "            last_hidden_state = output.last_hidden_state\n",
    "\n",
    "\n",
    "        last_hidden_state = last_hidden_state.reshape(( max_input_size, config.hidden_size))\n",
    "        mask = argument['attention_mask'].to(device).bool()\n",
    "        mask = mask.reshape(max_input_size)\n",
    "        mask = mask.nonzero().squeeze()\n",
    "        hidden_states = torch.index_select(last_hidden_state, 0, mask)\n",
    "        \n",
    "        #print(last_hidden_state)\n",
    "        inputs = get_mean_embedding(hidden_states.cpu().to(torch.float64).numpy()).tolist()\n",
    "        del last_hidden_state\n",
    "        del output\n",
    "        del mask\n",
    "        del hidden_states\n",
    "        del argument\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "                \n",
    "        embeddings.append(inputs)\n",
    "    # Return vector for [CLS] token\n",
    "    return embeddings\n",
    "\n",
    "def summerizeEmbeddings(brief):\n",
    "    embedding = sentence_model.encode(brief).tolist()\n",
    "    return embedding\n",
    "\n",
    "\n",
    "\n",
    "def get_mean_embedding(embedding):\n",
    "    return np.mean(embedding, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tfidf pipes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jd/_y9k6hnx4658pxlgs6r0d1pr0000gn/T/ipykernel_62893/1090808564.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testset['feature'].loc[testset[\"brief_type\"]==\"support\"] =   sparse_matrix.tolist()\n",
      "/var/folders/jd/_y9k6hnx4658pxlgs6r0d1pr0000gn/T/ipykernel_62893/1090808564.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testset['feature'].loc[testset[\"brief_type\"]==\"opposition\"] =   sparse_matrix.tolist()\n"
     ]
    }
   ],
   "source": [
    "model_name = \"KNN\"\n",
    "feature = 'tfidf'\n",
    "#for model_name in [\"RFT\", \"SGD\"]: #[\"KNN\",\"LinearSVC\", \"Logistic\", \"RFT\", \"SGD\"]:\n",
    "data = 'dataset/testset.csv'\n",
    "if True: #__name__ == \"__main__\":\n",
    "    model_types = [\"KNN\",\"LinearSVC\", \"Logistic\", \"RFT\", \"SGD\"]\n",
    "    # parser = argparse.ArgumentParser(description='End to end pipeline from briefs to predictions')\n",
    "    # parser.add_argument('--model_name', default='RFT', help=f'There are {len(model_types)} models to choose from: {model_types}')\n",
    "    # parser.add_argument('--data',  default= 'embeddings.csv')\n",
    "    # parser.add_argument('--feature', default='sentence_embeddings', help='There are two features to choose from: sentence_embeddings and tfidf')\n",
    "\n",
    "\n",
    "\n",
    "    # arg = parser.parse_args()\n",
    "\n",
    "    testset = pd.read_csv(data, index_col=0)#pd.read_csv(arg.data, index_col=0)\n",
    "\n",
    "    testset[\"completion\"] = list(map(lambda x : x.strip() ,testset[\"completion\"].to_list()))\n",
    "    \n",
    "\n",
    "    summerize = True\n",
    "\n",
    "    if feature == 'sentence_embeddings':#if arg.feature == 'sentence_embeddings':\n",
    "        if 'embeddings' not in testset.columns:\n",
    "            if not summerize:\n",
    "                model  = \"mistralai/Mistral-7B-v0.1\"\n",
    "                config = AutoConfig.from_pretrained(model)\n",
    "                max_input_size =  config.max_position_embeddings  \n",
    "                tokenizer = AutoTokenizer.from_pretrained(model, device=device, )\n",
    "\n",
    "                tokenizer.pad_token = tokenizer.eos_token\n",
    "                model = AutoModel.from_pretrained(model, torch_dtype= torch.bfloat16 ).to(device)  #,device_map = \"auto\"\n",
    "                #parallel_model = torch.nn.DataParallel(model)\n",
    "            else:\n",
    "                sentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "            testset['feature'] = \"\"\n",
    "            testset['feature'] = testset['prompt'].map(summerizeEmbeddings)\n",
    "            testset.to_csv('embeddings.csv')\n",
    "\n",
    "\n",
    "        else:\n",
    "            #get model for predictions\n",
    "            turn2list = lambda x: ast.literal_eval(x)\n",
    "            testset['feature'] = testset['embeddings'].map(turn2list)\n",
    "\n",
    "\n",
    "    elif feature == 'tfidf':# elif arg.feature == 'tfidf':\n",
    "        print(\"Loading tfidf pipes\")\n",
    "        support_pipe = joblib.load('pipes/support-tfidf.joblib')\n",
    "        opposition_pipe = joblib.load('pipes/oppose-tfidf.joblib')\n",
    "\n",
    "        testset['feature'] = \"\"\n",
    "\n",
    "        sparse_matrix = support_pipe.transform(testset[\"prompt\"].loc[testset[\"brief_type\"]==\"support\"]).toarray()\n",
    "\n",
    "        testset['feature'].loc[testset[\"brief_type\"]==\"support\"] =   sparse_matrix.tolist()\n",
    "\n",
    "        sparse_matrix = opposition_pipe.transform(testset[\"prompt\"].loc[testset[\"brief_type\"]==\"opposition\"]).toarray()\n",
    "\n",
    "        testset['feature'].loc[testset[\"brief_type\"]==\"opposition\"] =   sparse_matrix.tolist()\n",
    "        \n",
    "\n",
    "\n",
    "    x_support = np.array(testset[\"feature\"].loc[(testset[\"brief_type\"]==\"support\") & (testset[\"data_type\"]==\"test\") ].to_list())  #  np.array(testset['file_path'].to_list())\n",
    "    x_opposition = np.array(testset[\"feature\"].loc[(testset[\"brief_type\"]==\"opposition\") & (testset[\"data_type\"]==\"test\") ].to_list())  #  np.array(testset['file_path'].to_list())\n",
    "        \n",
    "\n",
    "    #get model for predictions\n",
    "\n",
    "    support_model_path = f'models/{model_name}-support-{feature}.pkl'\n",
    "    opposition_model_path = f'models/{model_name}-opposition-{feature}.pkl'\n",
    "\n",
    "    clfs = {\"sup\" : load(support_model_path)  , \"opp\" : load(opposition_model_path) }\n",
    "\n",
    "    if hasattr(clfs[\"sup\"], 'predict_proba') and callable(getattr(clfs[\"sup\"], 'predict_proba')):\n",
    "        scores_support = clfs['sup'].predict_proba(x_support)\n",
    "        scores_opposition = clfs['opp'].predict_proba(x_opposition)\n",
    "    else:\n",
    "        scores_support = clfs['sup'].decision_function(x_support)\n",
    "        scores_opposition = clfs['opp'].decision_function(x_opposition)\n",
    "\n",
    "    prediction_opposition = clfs['opp'].predict(x_opposition)\n",
    "    prediction_support = clfs['sup'].predict(x_support)\n",
    "\n",
    "    testset.rename(columns={\"file_name\": \"brief\",\"completion\": \"truth\"} , inplace = True  )\n",
    "\n",
    "    support = testset.loc[(testset[\"brief_type\"]==\"support\") & (testset[\"data_type\"]==\"test\") ].copy()\n",
    "    opposition = testset.loc[(testset[\"brief_type\"]==\"opposition\") & (testset[\"data_type\"]==\"test\") ].copy()\n",
    "\n",
    "    support.drop(['data_type','prompt' , 'brief_type','file_path','feature'], axis=1, inplace=True)\n",
    "    opposition.drop(['data_type', 'prompt' , 'brief_type','file_path','feature'], axis=1, inplace=True)\n",
    "\n",
    "    support['predict'] = \"\"\n",
    "    opposition['predict'] = \"\"\n",
    "\n",
    "    support['predict'] = prediction_support\n",
    "    opposition['predict'] = prediction_opposition\n",
    "\n",
    "    support['score'] = \"\"\n",
    "    opposition['score'] = \"\"\n",
    "\n",
    "    support['score'] = list(map( np.max ,scores_support.tolist()))\n",
    "    opposition['score']= list(map(  np.max ,scores_opposition.tolist() ))\n",
    "\n",
    "    support = support[[\"brief\",\"predict\",\"score\",\"truth\"]]\n",
    "    opposition = opposition[[\"brief\",\"predict\",\"score\",\"truth\"]]\n",
    "\n",
    "    support.to_csv(f'{model_name}-{feature}-supppredictions.csv' , index = False)\n",
    "    opposition.to_csv(f'{model_name}-{feature}-oppopredictions.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>brief_type</th>\n",
       "      <th>data_type</th>\n",
       "      <th>file_path</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Case 9:11-cv-80416-KLR Document 737 Entered on...</td>\n",
       "      <td>deny</td>\n",
       "      <td>support</td>\n",
       "      <td>train</td>\n",
       "      <td>1013</td>\n",
       "      <td>gov.uscourts.flsd.377721.737.0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Case 9:11-cv-80416-KLR Document 743 Entered on...</td>\n",
       "      <td>deny</td>\n",
       "      <td>opposition</td>\n",
       "      <td>train</td>\n",
       "      <td>1013</td>\n",
       "      <td>gov.uscourts.flsd.377721.743.0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IN THE UNITED STATES DISTRICT COURT\\nFOR THE S...</td>\n",
       "      <td>deny</td>\n",
       "      <td>support</td>\n",
       "      <td>train</td>\n",
       "      <td>909</td>\n",
       "      <td>gov.uscourts.mssd.95610.6.0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I i .\\nt | | , : tl\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n...</td>\n",
       "      <td>deny</td>\n",
       "      <td>opposition</td>\n",
       "      <td>train</td>\n",
       "      <td>909</td>\n",
       "      <td>gov.uscourts.mssd.95610.7.0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Case 1:08-cv-11908-RWZ Document 27\\n\\nFiled 09...</td>\n",
       "      <td>grant</td>\n",
       "      <td>support</td>\n",
       "      <td>train</td>\n",
       "      <td>507</td>\n",
       "      <td>gov.uscourts.mad.118796.27.0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>Case 6:10-cv-00111-LED Document 333\\n\\nFiled 0...</td>\n",
       "      <td>deny</td>\n",
       "      <td>opposition</td>\n",
       "      <td>test</td>\n",
       "      <td>621</td>\n",
       "      <td>gov.uscourts.txed.121829.333.0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>Helio LLC v. Palm, Inc. Doc. 3\\n\\n \\n\\n \\n\\n \\...</td>\n",
       "      <td>deny</td>\n",
       "      <td>support</td>\n",
       "      <td>train</td>\n",
       "      <td>574</td>\n",
       "      <td>gov.uscourts.cand.187342.3.0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>Helio LLC v. Palm, lnc.\\n\\n60373/2021440.1\\n\\n...</td>\n",
       "      <td>deny</td>\n",
       "      <td>opposition</td>\n",
       "      <td>train</td>\n",
       "      <td>574</td>\n",
       "      <td>gov.uscourts.cand.187342.9.0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>Case 1:11-cv-00696-RLW Document 4 Filed 04/08/...</td>\n",
       "      <td>grant</td>\n",
       "      <td>support</td>\n",
       "      <td>test</td>\n",
       "      <td>711</td>\n",
       "      <td>gov.uscourts.dcd.147524.4.0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>Case 1:11-cv-00696-RLW Document 22 Filed 04/28...</td>\n",
       "      <td>grant</td>\n",
       "      <td>opposition</td>\n",
       "      <td>test</td>\n",
       "      <td>711</td>\n",
       "      <td>gov.uscourts.dcd.147524.22.0.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt completion  \\\n",
       "0     Case 9:11-cv-80416-KLR Document 737 Entered on...       deny   \n",
       "1     Case 9:11-cv-80416-KLR Document 743 Entered on...       deny   \n",
       "2     IN THE UNITED STATES DISTRICT COURT\\nFOR THE S...       deny   \n",
       "3     I i .\\nt | | , : tl\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n...       deny   \n",
       "4     Case 1:08-cv-11908-RWZ Document 27\\n\\nFiled 09...      grant   \n",
       "...                                                 ...        ...   \n",
       "1210  Case 6:10-cv-00111-LED Document 333\\n\\nFiled 0...       deny   \n",
       "1211  Helio LLC v. Palm, Inc. Doc. 3\\n\\n \\n\\n \\n\\n \\...       deny   \n",
       "1212  Helio LLC v. Palm, lnc.\\n\\n60373/2021440.1\\n\\n...       deny   \n",
       "1213  Case 1:11-cv-00696-RLW Document 4 Filed 04/08/...      grant   \n",
       "1214  Case 1:11-cv-00696-RLW Document 22 Filed 04/28...      grant   \n",
       "\n",
       "      brief_type data_type  file_path                           file_name  \n",
       "0        support     train       1013  gov.uscourts.flsd.377721.737.0.txt  \n",
       "1     opposition     train       1013  gov.uscourts.flsd.377721.743.0.txt  \n",
       "2        support     train        909     gov.uscourts.mssd.95610.6.0.txt  \n",
       "3     opposition     train        909     gov.uscourts.mssd.95610.7.0.txt  \n",
       "4        support     train        507    gov.uscourts.mad.118796.27.0.txt  \n",
       "...          ...       ...        ...                                 ...  \n",
       "1210  opposition      test        621  gov.uscourts.txed.121829.333.0.txt  \n",
       "1211     support     train        574    gov.uscourts.cand.187342.3.0.txt  \n",
       "1212  opposition     train        574    gov.uscourts.cand.187342.9.0.txt  \n",
       "1213     support      test        711     gov.uscourts.dcd.147524.4.0.txt  \n",
       "1214  opposition      test        711    gov.uscourts.dcd.147524.22.0.txt  \n",
       "\n",
       "[1215 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = pd.read_csv('dataset/testset.csv', index_col=0)\n",
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jd/_y9k6hnx4658pxlgs6r0d1pr0000gn/T/ipykernel_62893/2777049630.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testset['tfidf'].loc[testset[\"brief_type\"]==\"support\"] =   sparse_matrix.tolist()\n",
      "/var/folders/jd/_y9k6hnx4658pxlgs6r0d1pr0000gn/T/ipykernel_62893/2777049630.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testset['tfidf'].loc[testset[\"brief_type\"]==\"opposition\"] =   sparse_matrix.tolist()\n"
     ]
    }
   ],
   "source": [
    "testset['tfidf'] = \"\"\n",
    "\n",
    "\n",
    "sparse_matrix = pipe.transform(testset[\"prompt\"].loc[testset[\"brief_type\"]==\"support\"]).toarray()\n",
    "\n",
    "testset['tfidf'].loc[testset[\"brief_type\"]==\"support\"] =   sparse_matrix.tolist()\n",
    "\n",
    "sparse_matrix = pipe.transform(testset[\"prompt\"].loc[testset[\"brief_type\"]==\"opposition\"]).toarray()\n",
    "\n",
    "testset['tfidf'].loc[testset[\"brief_type\"]==\"opposition\"] =   sparse_matrix.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'feature'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/oluwaseuncardoso/Desktop/Projects/PytorchLearning/OpenAI/motion_prediction/prescript.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oluwaseuncardoso/Desktop/Projects/PytorchLearning/OpenAI/motion_prediction/prescript.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m arg \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mfeature\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtfidf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mKNN\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39membeddings.csv\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oluwaseuncardoso/Desktop/Projects/PytorchLearning/OpenAI/motion_prediction/prescript.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m arg\u001b[39m.\u001b[39;49mfeature\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'feature'"
     ]
    }
   ],
   "source": [
    "arg = {\"feature\": \"tfidf\", \"model_type\": \"KNN\", \"data\": \"embeddings.csv\"}\n",
    "\n",
    "arg.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. run experiment with the last hidden state with just support\n",
    "# TFI-DF and Mistral7 embeddings, the claim is there isn't any statistical difference between the two\n",
    "# hypothesis,\n",
    "\n",
    "    # is having more information better than less information in classification\n",
    "#hypothesis 1:\n",
    "    # having more information is better than less information\n",
    "#hypotheisis 2:\n",
    "    # are TFI-DF embeddings better than Mistral7 embeddings\n",
    "# After running experiment s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
